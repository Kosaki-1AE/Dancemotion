import csv
import os
import pathlib
import subprocess
import time
from collections import deque
from datetime import datetime

import cv2
import librosa
import matplotlib.pyplot as plt
import numpy as np
import sounddevice as sd
import soundfile as sf
from matplotlib import rcParams

# ---- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆmatplotlibç”¨ï¼‰ ----
rcParams['font.family'] = 'MS Gothic'

# ---- éŸ³å£°è¨­å®š ----
SAMPLING_RATE = 22050
BLOCK_SIZE = 2048
volume_level = 0.0
audio_buffer = deque(maxlen=BLOCK_SIZE)

# ---- ãƒ­ã‚°ãƒ»å‹•ç”»ãƒ»éŸ³å£°ãƒ•ã‚©ãƒ«ãƒ€ã®æº–å‚™ ----
base_dir = pathlib.Path(__file__).resolve().parent.parent
log_dir = base_dir / "log"
video_dir = base_dir / "video"
os.makedirs(log_dir, exist_ok=True)
os.makedirs(video_dir, exist_ok=True)

# ---- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— ----
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# ---- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ç”¨ãƒªã‚¹ãƒˆã¨ãƒ‡ãƒã‚¤ã‚¹é¸æŠ ----
audio_record = []

devices = sd.query_devices()
mic_device = None
for i, dev in enumerate(devices):
    if dev['max_input_channels'] > 0 and ("usb" in dev['name'].lower() or "external" in dev['name'].lower()):
        mic_device = i
        break
if mic_device is None:
    mic_device = sd.default.device[0]

# ---- éŸ³å£°éŒ²éŸ³ç”¨ ----
def audio_record_callback(indata, frames, time, status):
    audio_buffer.extend(indata[:, 0])
    audio_record.append(indata.copy())
    global volume_level
    volume_level = np.linalg.norm(indata[:, 0]) / frames

audio_stream = sd.InputStream(samplerate=SAMPLING_RATE, channels=1, callback=audio_record_callback, device=mic_device, blocksize=BLOCK_SIZE)
audio_stream.start()

# ---- æ˜ åƒä¿å­˜ ----
cap = cv2.VideoCapture(0)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

# ä»®ã®FPSï¼ˆã‚ã¨ã§ä¸Šæ›¸ãï¼‰
video_filename = video_dir / f"stillness_video_{timestamp}.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(str(video_filename), fourcc, 1.0, (frame_width, frame_height))

# ---- CSVãƒ•ã‚¡ã‚¤ãƒ«æº–å‚™ ----
csv_filename = log_dir / f"stillness_log_{timestamp}.csv"
with open(csv_filename, 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["time", "motion", "volume", "stillness_score", "label"])

# ---- åˆæœŸåŒ– ----
prev_frame = None
motion_buffer = deque(maxlen=100)
vol_buffer = deque(maxlen=100)
score_buffer = deque(maxlen=100)
label_buffer = deque(maxlen=100)

plt.ion()
fig, axs = plt.subplots(4, 1, figsize=(8, 10))

def classify_stillness(score):
    if score > 0.7:
        return "Silent"
    elif score > 0.4:
        return "Neutral"
    else:
        return "Noisy"

# ---- FPSæ¸¬å®šç”¨ ----
frame_count = 0
start_time = time.time()

# ---- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ----
while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (21, 21), 0)
    if prev_frame is None:
        prev_frame = blur
        continue

    frame_delta = cv2.absdiff(prev_frame, blur)
    motion_intensity = np.sum(frame_delta) / 1000000
    motion_intensity = np.clip(motion_intensity, 0, 1)
    prev_frame = blur

    vol = np.clip(volume_level, 0, 1)
    score = (1 - vol) * (1 - motion_intensity)
    label = classify_stillness(score)

    current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3]
    with open(csv_filename, 'a', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow([current_time, motion_intensity, vol, score, label])

    motion_buffer.append(motion_intensity)
    vol_buffer.append(vol)
    score_buffer.append(score)
    label_buffer.append(label)

    axs[0].cla()
    axs[0].plot(motion_buffer)
    axs[0].set_title("Motion Intensity")

    axs[1].cla()
    axs[1].plot(vol_buffer)
    axs[1].set_title("Sound Volume")

    axs[2].cla()
    axs[2].plot(score_buffer, color='purple')
    axs[2].set_title("Stillness in Motion")

    axs[3].cla()
    if len(audio_buffer) >= BLOCK_SIZE:
        y = np.array(audio_buffer, dtype=np.float32)
        mel_spec = librosa.feature.melspectrogram(y=y, sr=SAMPLING_RATE, n_mels=40, fmax=8000)
        mel_db = librosa.power_to_db(mel_spec, ref=np.max)
        axs[3].imshow(mel_db, aspect='auto', origin='lower', cmap='magma')
        axs[3].set_title("Mel-Spectrogram")

    plt.tight_layout()
    plt.pause(0.01)

    display_text = f"Stillness in Motion: {score:.2f} ({label})"
    cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)
    cv2.imshow("Live", frame)
    out.write(frame)

    frame_count += 1
    if cv2.waitKey(1) & 0xFF == 27:
        break

# ---- çµ‚äº†å‡¦ç† ----
cap.release()
out.release()
cv2.destroyAllWindows()

audio_stream.stop()
audio_stream.close()
audio_data = np.concatenate(audio_record, axis=0)
audio_filename = video_dir / f"stillness_audio_{timestamp}.wav"
sf.write(audio_filename, audio_data, SAMPLING_RATE)

# ---- å®Ÿæ¸¬FPSè¨ˆç®— ----
elapsed_time = time.time() - start_time
actual_fps = frame_count / elapsed_time
print(f"ğŸ¯ å®Ÿæ¸¬FPS: {actual_fps:.2f}")

# ---- ffmpegã§éŸ³å£°ä»˜ãå‹•ç”»ã«å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆFPSåæ˜ ï¼‰ ----
final_filename = video_dir / f"stillness_final_{timestamp}.mp4"
subprocess.call([
    "ffmpeg",
    "-y",
    "-r", f"{actual_fps:.2f}",
    "-i", str(video_filename),
    "-i", str(audio_filename),
    "-c:v", "copy",
    "-c:a", "aac",
    "-strict", "experimental",
    str(final_filename)
])
