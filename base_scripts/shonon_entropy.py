# -*- coding: utf-8 -*-
# Video Ã— Audio Shannon Fusion for Real-time Stillness
# ã—ã‚ƒãã—ã‚ƒãä»•æ§˜ï¼š
# - æ˜ åƒï¼šã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã®å¤§ãã•ãƒ’ã‚¹ãƒˆ â†’ Shannonã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆæºã‚‰ãï¼‰
# - éŸ³å£°ï¼šçŸ­æ™‚é–“ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆãƒ‘ãƒ¯ãƒ¼ï¼‰ãƒ’ã‚¹ãƒˆ â†’ Shannonã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼ˆæºã‚‰ãï¼‰
# - ãƒ•ã‚¡ã‚¸ã‚£åˆæˆ + ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ + æ»ç•™ + å…¥é€€å ´ã‚²ãƒ¼ãƒˆã§â€œäººé–“ã£ã½ã„åœæ­¢â€åˆ¤å®š
#
# ä¾å­˜:
#   pip install opencv-python numpy sounddevice
#
# å®Ÿè¡Œ:
#   python nori_rt_av_shannon.py   # ESCã§çµ‚äº†
#
# ãƒ¡ãƒ¢:
# - ã‚«ãƒ¡ãƒ©/ãƒã‚¤ã‚¯ã®ãƒ‡ãƒã‚¤ã‚¹IDã¯ç’°å¢ƒã«ã‚ˆã£ã¦ç•°ãªã‚‹ã®ã§CFGã§èª¿æ•´ã—ã¦ã­
# - ã¾ãšã¯Shannonã ã‘ã€‚è¦–ç·š/è¡¨æƒ…ã®æ‹¡å¼µã¯å¾Œã‹ã‚‰è¶³ã—ã‚„ã™ã„éª¨æ ¼ã«ã—ã¦ã¾ã™

import cv2 as cv
import numpy as np
import sounddevice as sd
import queue, threading, time
from collections import deque

# =========================
# CONFIGï¼ˆç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
# =========================
CFG = dict(
    # Video
    cam_id=0,
    frame_size=(640, 360),
    flow_deadzone=0.03,         # å¾®æŒ¯å‹•ã‚«ãƒƒãƒˆï¼ˆ0.02ã€œ0.06ã§èª¿æ•´ï¼‰
    flow_bins=12,               # ãƒ’ã‚¹ãƒˆãƒ“ãƒ³
    flow_clip_percentile=99.0,  # å¤–ã‚Œå€¤ã‚«ãƒƒãƒˆ
    flow_ema=0.25,              # Hã®EMA

    # Audio
    sr=16000,                   # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°
    blocksize=512,              # 1ãƒ–ãƒ­ãƒƒã‚¯ã‚ãŸã‚Šã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆç´„32ms@16kHzï¼‰
    audio_bins=32,              # ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ’ã‚¹ãƒˆã®ãƒ“ãƒ³
    audio_ema=0.35,             # éŸ³å£°Hã®EMA
    audio_device=None,          # ä½¿ã†å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹IDï¼ˆNoneã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
    audio_gain=1.0,             # å…¥åŠ›ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆã‚¯ãƒªãƒƒãƒ—å¯¾ç­–ï¼‰

    # Fusion & Decision
    w_video=0.6,                # Hèåˆã®é‡ã¿ï¼ˆæ˜ åƒå´ï¼‰
    w_audio=0.4,                # Hèåˆã®é‡ã¿ï¼ˆéŸ³å£°å´ï¼‰
    dwell_frames=45,            # Stillåˆ¤å®šã«å¿…è¦ãªç¶™ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ~1.5ç§’@30fpsï¼‰
    enter_thresh=0.50,          # ã“ã‚Œã‚’è¶…ãˆãŸã‚‰Stillå€™è£œï¼ˆ0ã€œ1, é«˜ã„=å³ã—ã‚ï¼‰
    exit_thresh=0.60,           # ã“ã‚Œã‚’ä¸‹å›ã£ãŸã‚‰è§£é™¤ï¼ˆ0ã€œ1ï¼‰

    # Entry/Exit Gateï¼ˆå…¥ã‚‹/æƒã‘ã‚‹ç¬é–“ã®æš´ç™ºæŠ‘åˆ¶ï¼‰
    gate_fg_delta=0.08,         # å‰æ™¯é¢ç©ã®æ€¥å¤‰ã—ãã„
    gate_luma_delta=12.0,       # è¼åº¦å¹³å‡ã®æ€¥å¤‰ã—ãã„
    gate_frames=20,             # ä¸å¿œãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ~0.7ç§’@30fpsï¼‰

    # UI
    H_display_max=3.5,
)

# =========================
# Utility
# =========================
def shannon_entropy_from_hist(h, eps=1e-12):
    p = h / (np.sum(h) + eps)
    p = np.clip(p, eps, 1.0)
    return -np.sum(p * np.log(p))  # nats

def ema(prev, x, a):
    return x if prev is None else (a*x + (1-a)*prev)

def fuzzy_low(value, low, high):
    """ä½ã„ã»ã©â€œè‰¯ã„â€ï¼ˆ=Stillå¯„ä¸ï¼‰ã‚’ [0,1] ã«ç·šå½¢ãƒãƒƒãƒ—"""
    return float(np.clip((high - value) / (high - low + 1e-9), 0, 1))

def draw_meter(frame, value, min_v, max_v, x, y, w, h, label, color=(0,200,0)):
    v = (value - min_v) / (max_v - min_v + 1e-9)
    v = float(np.clip(v, 0, 1))
    cv.rectangle(frame, (x, y), (x+w, y+h), (60,60,60), 1)
    cv.rectangle(frame, (x, y), (x+int(w*v), y+h), color, -1)
    cv.putText(frame, f"{label}: {value:.3f}", (x, y-6),
               cv.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1, cv.LINE_AA)

# =========================
# Audio Streamï¼ˆéåŒæœŸï¼‰
# =========================
audio_q = queue.Queue()

def audio_callback(indata, frames, time_info, status):
    if status:
        # ãƒ‰ãƒ­ãƒƒãƒ—/OVERRUNç­‰ã¯ãƒ­ã‚°ã ã‘
        print(status)
    # 1chã«æƒãˆã‚‹
    data = indata.copy()
    if data.ndim == 2 and data.shape[1] > 1:
        data = data.mean(axis=1, keepdims=True)
    audio_q.put(data)

def start_audio_stream():
    stream = sd.InputStream(
        channels=1,
        samplerate=CFG["sr"],
        blocksize=CFG["blocksize"],
        device=CFG["audio_device"],
        callback=audio_callback,
        dtype='float32'
    )
    stream.start()
    return stream

def audio_shannon(block, bins=32):
    # block: shape (N,1)
    x = (block[:,0] * CFG["audio_gain"]).astype(np.float32)
    # çª“é–¢æ•°ï¼ˆãƒãƒ³ï¼‰
    win = np.hanning(len(x)).astype(np.float32)
    X = np.abs(np.fft.rfft(x * win))**2
    if not np.isfinite(X).any() or np.max(X) <= 0:
        return 0.0
    # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«ã—ãªã„ä»£ã‚ã‚Šã«ç¯„å›²ã‚’å‹•çš„ã«
    h, _ = np.histogram(X, bins=bins, range=(0, np.percentile(X, 99)+1e-6))
    return shannon_entropy_from_hist(h)

# =========================
# Videoæº–å‚™
# =========================
cap = cv.VideoCapture(CFG["cam_id"])
assert cap.isOpened(), "ã‚«ãƒ¡ãƒ©é–‹ã‘ãªã„ğŸ¥²"
prev_gray = None

# å…¥é€€å ´ã‚²ãƒ¼ãƒˆ
bg = cv.createBackgroundSubtractorMOG2(history=300, varThreshold=16, detectShadows=True)
refractory = 0
prev_fg_ratio = None
prev_luma = None

# çŠ¶æ…‹
H_video_ema = None
H_audio_ema = None
still_counter = 0
state = "MOTION"

# Audio start
stream = start_audio_stream()

# Optical Flow params
flow_params = dict(
    pyr_scale=0.5, levels=3, winsize=15,
    iterations=3, poly_n=5, poly_sigma=1.2, flags=0
)

# =========================
# Main Loop
# =========================
try:
    while True:
        ok, frame = cap.read()
        if not ok:
            break
        frame = cv.resize(frame, CFG["frame_size"])
        gray  = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        gray  = cv.GaussianBlur(gray, (3,3), 0)  # éœ²å‡ºã‚†ã‚Œãƒ»ç ‚ãƒã‚¤ã‚ºæŠ‘ãˆ

        # ---- å…¥é€€å ´ã‚²ãƒ¼ãƒˆï¼ˆæ€¥å¤‰ã§ä¸å¿œï¼‰----
        mask_bg = bg.apply(gray)
        fg_ratio = float(np.count_nonzero(mask_bg==255)) / mask_bg.size
        luma = float(np.mean(gray))
        if prev_fg_ratio is not None and abs(fg_ratio - prev_fg_ratio) > CFG["gate_fg_delta"]:
            refractory = CFG["gate_frames"]
        if prev_luma is not None and abs(luma - prev_luma) > CFG["gate_luma_delta"]:
            refractory = CFG["gate_frames"]
        prev_fg_ratio, prev_luma = fg_ratio, luma

        # ---- æ˜ åƒH: ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã®å¤§ãã•ãƒ’ã‚¹ãƒˆ ----
        if prev_gray is None:
            prev_gray = gray.copy()
            cv.putText(frame, "warming up...", (20, 36),
                       cv.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)
            cv.imshow("Nori AV Shannon", frame)
            if cv.waitKey(1) & 0xFF == 27: break
            continue

        flow = cv.calcOpticalFlowFarneback(prev_gray, gray, None, **flow_params)
        fx, fy = flow[...,0], flow[...,1]
        mag = np.sqrt(fx*fx + fy*fy)
        # ã‚¯ãƒªãƒƒãƒ—ï¼†ãƒ‡ãƒƒãƒ‰ã‚¾ãƒ¼ãƒ³
        mag_max = np.percentile(mag, CFG["flow_clip_percentile"]) + 1e-6
        mag = np.clip(mag, 0, mag_max)
        mag[mag < CFG["flow_deadzone"]] = 0.0

        h_flow, _ = np.histogram(mag, bins=CFG["flow_bins"], range=(0, mag_max))
        H_video = shannon_entropy_from_hist(h_flow)
        H_video_ema = ema(H_video_ema, H_video, CFG["flow_ema"])

        # ---- éŸ³å£°H: ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‘ãƒ¯ãƒ¼ã®ãƒ’ã‚¹ãƒˆ ----
        H_audio = None
        try:
            audio_block = audio_q.get_nowait()
            H_audio = audio_shannon(audio_block, bins=CFG["audio_bins"])
            H_audio_ema = ema(H_audio_ema, H_audio, CFG["audio_ema"])
        except queue.Empty:
            pass

        # ---- ãƒ•ã‚¡ã‚¸ã‚£åŒ–ï¼ˆä½Hã»ã©Stillå¯„ä¸ï¼‰----
        # ã—ãã„ã¯çµŒé¨“çš„ã«ï¼šæ˜ åƒH ~ [0.3, 1.2] / éŸ³å£°H ~ [2, 5]ï¼ˆãƒ‡ãƒ¼ã‚¿ã§èª¿æ•´ã—ã¦ã­ï¼‰
        f_video = fuzzy_low(H_video_ema if H_video_ema is not None else 0.0, 0.35, 1.10)
        if H_audio_ema is not None:
            f_audio = fuzzy_low(H_audio_ema, 2.0, 5.0)
        else:
            f_audio = 0.5  # éŸ³å£°æœªå–å¾—æ™‚ã¯ä¸­ç«‹

        # ---- èåˆï¼ˆç©ã§ã‚‚å’Œã§ã‚‚OKã€‚ã“ã“ã¯å’Œâ†’æ­£è¦åŒ–ï¼‰----
        fused = CFG["w_video"]*(1-f_video) + CFG["w_audio"]*(1-f_audio)  # â€œä¸å®‰å®šåº¦â€ã®é‡ã¿ä»˜ãå’Œ
        fused = float(np.clip(fused, 0, 1))
        # Stillåº¦ï¼ˆ1ã«è¿‘ã„ã»ã©é™ï¼‰
        still_score = 1.0 - fused

        # ---- ä¸å¿œã‚²ãƒ¼ãƒˆ + æ»ç•™ + ãƒ’ã‚¹ãƒ†ãƒªã‚·ã‚¹ ----
        gate_text = ""
        if refractory > 0:
            refractory -= 1
            state = "MOTION"
            still_counter = 0
            gate_text = f"GATED {refractory}"
        else:
            if state == "MOTION":
                if still_score > (1.0 - CFG["enter_thresh"]):
                    still_counter += 1
                    if still_counter >= CFG["dwell_frames"]:
                        state = "STILL"
                        still_counter = 0
                else:
                    still_counter = 0
            else:
                if still_score < (1.0 - CFG["exit_thresh"]):
                    state = "MOTION"

        # ---- UI ----
        label = f"STATE: {state}"
        color = (0,255,0) if state=="STILL" else (0,0,255)
        cv.putText(frame, label, (20, 28), cv.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv.LINE_AA)
        if gate_text:
            cv.putText(frame, gate_text, (20, 52), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2, cv.LINE_AA)

        draw_meter(frame, H_video_ema if H_video_ema is not None else 0.0,
                   0.0, CFG["H_display_max"], 20, 80, 260, 16, "H_video (nats)")
        if H_audio_ema is not None:
            draw_meter(frame, H_audio_ema, 0.0, 6.0, 20, 105, 260, 16, "H_audio (nats)", (0,180,200))
        draw_meter(frame, still_score, 0.0, 1.0, 20, 130, 260, 16, "Stillness score", (0,255,255))

        # çŸ¢å°ãƒ‡ãƒãƒƒã‚°ï¼ˆé‡ã„ãªã‚‰OFFï¼‰
        step = 24
        h, w = gray.shape
        for yy in range(0, h, step):
            for xx in range(0, w, step):
                dx, dy = flow[yy, xx]
                cv.arrowedLine(frame,(xx,yy),(int(xx+dx),int(yy+dy)),(180,180,50),1,tipLength=0.3)

        cv.imshow("Nori AV Shannon", frame)
        prev_gray = gray

        if cv.waitKey(1) & 0xFF == 27:
            break

finally:
    cap.release()
    stream.stop()
    cv.destroyAllWindows()
