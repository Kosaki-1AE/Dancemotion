# conversation_engine.py
# ã—ã‚ƒãã—ã‚ƒãæµ 4å±¤ã‚¢ãƒ¼ã‚­ï¼ˆGenesys/Stillness/Motion/Coherenceï¼‰+ ä¼šè©±ãƒ«ãƒ¼ãƒ—
# - Genesys: ãƒ•ã‚¡ã‚¸ã‚£æ¨è«–ã§ã€Œç›¸æ‰‹ã®çŠ¶æ…‹ã€ã€Œè©±é¡Œæ„å›³ã€ã€Œæ¸©åº¦æ„Ÿã€ã‚’ä»®èª¬ç”Ÿæˆ
# - Stillness: ä¸ç¢ºã‹ã•Ã—ç†±é‡ã§ã‚²ã‚¤ãƒ³åˆ¶å¾¡ã€å¾…æ©Ÿ/åå°„/å³å¿œã‚’æ±ºå®š
# - Motion: è¡Œå‹•ãƒ†ãƒ³ãƒ—ãƒ¬ï¼ˆè³ªå•/å…±æ„Ÿ/è¦ç´„/ææ¡ˆ/å†—è«‡/å¢ƒç•Œå®£è¨€ï¼‰ã‚’ãƒ‘ãƒ©ä»˜ãç”Ÿæˆ
# - Coherence: è¿”å ±ï¼ˆæ¥µç°¡æ˜“ã‚¹ã‚³ã‚¢ï¼‰ã§æ–¹ç­–ã‚’æ›´æ–°ï¼†æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯

import dataclasses
import json
import math
import os
import random
import time
from collections import deque
from dataclasses import dataclass, field
from typing import Any, Dict, List, Tuple


# -------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------------
def clamp(x, a, b): return max(a, min(b, x))
def sigmoid(x): return 1/(1+math.exp(-x))

# -------------------------
# ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆYAMLé¢¨ã®æ—¢å®šå€¤ï¼‰
# -------------------------
DEFAULT_YAML = """
persona:
  name: "ã—ã‚ƒãã‚¢ãƒ¼ã‚­"
  vibe: "ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼/ç´ æ—©ã„ãƒ¦ãƒ¼ãƒ¢ã‚¢/çŸ­æ–‡å„ªå…ˆ"
goals:
  - "ç›¸æ‰‹ã®å®‰å¿ƒæ„Ÿã‚’å®ˆã‚‹"
  - "ä¼šè©±ã®æ¸©åº¦ã‚’é©æ­£åŒ–ã™ã‚‹"
  - "ä»®èª¬â†’æ¤œè¨¼ã®é€Ÿã„ãƒ«ãƒ¼ãƒ—ã‚’å›ã™"
genesys:
  fuzzy_sets:
    heat:     {low:[0,0,0.3], mid:[0.2,0.5,0.8], high:[0.6,1.0,1.0]}
    clarity:  {low:[0,0,0.4], mid:[0.3,0.6,0.9], high:[0.7,1.0,1.0]}
    affect:   {neg:[0,0,0.4], neutral:[0.3,0.5,0.7], pos:[0.6,1.0,1.0]}
  rules:
    - if: {heat: high, clarity: low}       # ç››ã‚Šä¸ŠãŒã‚Šå¼·ã„Ã—è«–ç‚¹æ›–æ˜§
      then: {intent: "narrow", confidence: 0.7}
    - if: {heat: mid, clarity: mid}
      then: {intent: "progress", confidence: 0.6}
    - if: {heat: low, clarity: low}
      then: {intent: "open", confidence: 0.6}
    - if: {affect: neg}
      then: {intent: "de-escalate", confidence: 0.8}
stillness:
  gain:
    base: 0.6         # è¿”ç­”ã®æ”»ã‚åº¦åˆã„
    wait_bias: 0.2    # å¾…ã¤æ–¹å‘ã®åˆæœŸãƒã‚¤ã‚¢ã‚¹
    entropy_weight: 0.7
    heat_weight: 0.3
  wait_window_sec: [1.0, 3.0]  # åå°„å‰ã«ç½®ãç„¡å¿œç­”ã®æºã‚‰ã
motion:
  templates:
    open:        ["ã©ã®è¾ºãŒæ°—ã«ãªã£ã¦ã‚‹ï¼Ÿ", "ã¾ãšã–ã£ãã‚ŠèããŸã„ï¼š{echo}?"]
    narrow:      ["ä¸€ç•ªå¤§äº‹ãªã®ã¯{key}ã§åˆã£ã¦ã‚‹ï¼Ÿ", "{key}ã«çµã£ã¦æ·±æ˜ã‚Šã—ã‚ˆã€‚"]
    progress:    ["ä»Šã®ã§åŠåˆ†é€²ã‚“ã ã€‚æ¬¡ã¯{next}ã„ã“ã€‚", "ã„ã„æ„Ÿã˜ã€‚{next}ã‚„ã£ã¦ã¿ã‚‹ï¼Ÿ"]
    de-escalate: ["ã„ã£ãŸã‚“å‘¼å¸åˆã‚ã›ã‚ˆã€‚ç„¡ç†ã›ãšã§â—", "OKã€ãƒšãƒ¼ã‚¹è½ã¨ã™ã­ã€‚ä½•ãŒã—ã‚“ã©ã„ï¼Ÿ"]
    empathize:   ["ãã‚Œã€ã‚ã‹ã‚‹ã€‚ä¿ºã‚‚ä¼¼ãŸã¨ã“åˆºã•ã‚‹ã€‚", "å…±æ„Ÿãƒã‚¤ãƒ³ãƒˆï¼š{echo}"]
    joke:        ["ã¡ã‚‡ã„å°ãƒã‚¿ï¼š{quip}", "ã“ã‚Œã¯â€¦ãƒ„ãƒƒã‚³ãƒŸå¾…ã¡ï¼Ÿç¬‘"]
    boundary:    ["ã“ã“ã¯ç·šå¼•ã„ã¨ã“ã€‚{rule}", "å®‰å…¨ã®ãŸã‚{rule}ã§é€²ã‚ã‚ˆã€‚"]
coherence:
  reward:
    k_pos: 1.0
    k_neu: 0.2
    k_neg: -1.2
  consistency_penalty: 0.15
storage:
  path: "conv_state.json"
"""

# -------------------------
# ç°¡æ˜“ YAML ãƒ‘ãƒ¼ã‚µï¼ˆä¾å­˜ã‚¼ãƒ­ï¼‰
# -------------------------
import re


def parse_yaml(s: str) -> Dict[str, Any]:
    # ã–ã£ãã‚ŠJSONåŒ–ï¼ˆä»Šå›ã®æ—¢å®šå€¤å‰æã®è¶…ç°¡æ˜“ï¼‰
    import yaml as _yy  # ã‚‚ã—PyYAMLãªã‘ã‚Œã°ã“ã“ã‚’æ‰‹æ›¸ãå¤‰æ›ã«å·®ã—æ›¿ãˆ
    return _yy.safe_load(s)

try:
    import yaml  # type: ignore
except:
    # æœ€ä½é™ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆç’°å¢ƒã«PyYAMLç„¡ã‘ã‚Œã°å°å®Ÿè£…ï¼‰
    def yaml_safe_load(s): return json.loads(json.dumps(parse_yaml(s)))  # ä¸ä½¿ç”¨
    pass

# -------------------------
# ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
# -------------------------
@dataclass
class Turn:
    user: str
    bot: str = ""
    heat: float = 0.5     # ãƒ’ãƒ¼ãƒˆï¼ˆä¸»è¦³ï¼‰
    clarity: float = 0.5  # æ˜ç­ã•
    affect: float = 0.5   # ãƒã‚¸åº¦ï¼ˆ0=ãƒã‚¬,1=ãƒã‚¸ï¼‰
    intent: str = "open"
    reward: float = 0.0

@dataclass
class Memory:
    turns: deque = field(default_factory=lambda: deque(maxlen=50))
    policy_scores: Dict[str, float] = field(default_factory=lambda: {
        "open":0.0,"narrow":0.0,"progress":0.0,"de-escalate":0.0,
        "empathize":0.0,"joke":0.0,"boundary":0.0
    })

# -------------------------
# Genesysï¼ˆãƒ•ã‚¡ã‚¸ã‚£æ¨è«–ï¼‰
# -------------------------
class Genesys:
    def __init__(self, cfg):
        self.cfg = cfg
        self.fs = cfg["fuzzy_sets"]

    @staticmethod
    def tri(x,a,b,c):
        if x<=a or x>=c: return 0.0
        if x==b: return 1.0
        return (x-a)/(b-a) if x<b else (c-x)/(c-b)

    def fuzzify(self, x, setdef):
        # setdef: {"low":[0,0,0.3], "mid":[..], ...}
        mu = {}
        for name, tri in setdef.items():
            mu[name] = self.tri(x, tri[0], tri[1], tri[2])
        return mu

    def infer(self, text:str, estimates:Dict[str,float]) -> Tuple[str,float,Dict]:
        """ textã¯ä½¿ã‚ãšã«æœ€å°æ©Ÿèƒ½ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è»½å¾®è£œæ­£ï¼‰ """
        heat = estimates.get("heat",0.5)
        clarity = estimates.get("clarity",0.5)
        affect = estimates.get("affect",0.5)

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯è£œæ­£ï¼ˆä¾‹ï¼šæ‹/å‘Šç™½â†’heatâ†‘ï¼‰
        t = text.lower()
        if any(k in t for k in ["å‘Šç™½","ã‚¢ãƒ”ãƒ¼ãƒ«","å¥½ã","love"]):
            heat = clamp(heat+0.15,0,1)
        if any(k in t for k in ["ä¸å®‰","ãƒ ã‚ºã„","ç„¡ç†"]):
            affect = clamp(affect-0.2,0,1)

        mu_heat    = self.fuzzify(heat,    self.fs["heat"])
        mu_clarity = self.fuzzify(clarity, self.fs["clarity"])
        mu_affect  = self.fuzzify(affect,  self.fs["affect"])

        best_intent, best_conf = "open", 0.5
        chosen_rule = None
        for rule in self.cfg["rules"]:
            cond = rule["if"]
            mlist=[]
            for k,v in cond.items():
                if k=="heat":    mlist.append(mu_heat[v])
                if k=="clarity": mlist.append(mu_clarity[v])
                if k=="affect":  mlist.append(mu_affect[v])
            fire = min(mlist) if mlist else 0.0
            conf = rule["then"]["confidence"] * fire
            if conf>best_conf:
                best_conf = conf
                best_intent = rule["then"]["intent"]
                chosen_rule = rule

        return best_intent, best_conf, {
            "heat":heat, "clarity":clarity, "affect":affect,
            "mu": {"heat":mu_heat,"clarity":mu_clarity,"affect":mu_affect},
            "rule": chosen_rule
        }

# -------------------------
# Stillnessï¼ˆã‚²ã‚¤ãƒ³åˆ¶å¾¡ï¼‹å¾…æ©Ÿï¼‰
# -------------------------
class Stillness:
    def __init__(self, cfg):
        self.g = cfg["gain"]
        self.wait_rng = cfg["wait_window_sec"]

    def decide(self, intent:str, conf:float, est:Dict[str,float]) -> Dict[str,Any]:
        entropy = -sum(p*math.log(p+1e-9) for p in [
            est["heat"], est["clarity"], est["affect"]
        ])/math.log(3)  # 0..1 æ­£è¦åŒ–

        gain = self.g["base"]
        gain -= self.g["entropy_weight"]*entropy
        gain += self.g["heat_weight"]*est["heat"]
        gain = clamp(gain,0,1)

        wait_prob = clamp(self.g["wait_bias"] + 0.6*(1-conf) + 0.3*entropy, 0, 1)
        will_wait = (random.random() < wait_prob)
        wait_sec = random.uniform(*self.wait_rng) if will_wait else 0.0

        return {"gain":gain, "wait":will_wait, "wait_sec":wait_sec,
                "entropy":entropy, "wait_prob":wait_prob}

# -------------------------
# Motionï¼ˆè¡Œå‹•ãƒ†ãƒ³ãƒ—ãƒ¬ï¼‰
# -------------------------
class Motion:
    def __init__(self, cfg):
        self.templates = cfg["templates"]
        self.quips = ["ãã‚Œã¯ç§’ã§å„ªå‹ã§ã¯ï¼Ÿ", "è„³å†…ã§æ‹æ‰‹èµ·ããŸã‚", "ãã‚Œã‚¨ã‚°ã„w"]
        self.rules = [
            ("boundary", lambda ctx: ctx["gain"]<0.25),
            ("de-escalate", lambda ctx: ctx["entropy"]>0.7),
        ]

    def choose_policy(self, intent:str, ctx:Dict[str,Any]) -> str:
        # ãƒ«ãƒ¼ãƒ«å„ªå…ˆã§ä¸Šæ›¸ã
        for name,cond in self.rules:
            if cond(ctx): return name
        return intent

    def render(self, policy:str, vars:Dict[str,str]) -> str:
        bank = self.templates.get(policy, ["{echo}"])
        tmpl = random.choice(bank)
        return tmpl.format(**vars)

# -------------------------
# Coherenceï¼ˆå ±é…¬ï¼‹æ•´åˆãƒã‚§ãƒƒã‚¯ï¼‰
# -------------------------
class Coherence:
    def __init__(self, cfg):
        self.k = cfg["reward"]
        self.penalty = cfg["consistency_penalty"]

    def score_turn(self, user_text:str, bot_text:str, est:Dict[str,float], intent:str) -> float:
        # ã–ã£ãã‚Šæ„Ÿæƒ…ã‚¹ã‚³ã‚¢ï¼šçµµæ–‡å­—ãƒ»è‚¯å®šèªã§è¿‘ä¼¼
        pos = sum(user_text.count(x) for x in ["ğŸ‘","ğŸ˜Š","åŠ©ã‹ã‚‹","ã„ã„ã­","ãªã‚‹ã»ã©","è‰"])
        neg = sum(user_text.count(x) for x in ["ç„¡ç†","æœ€æ‚ª","ã¯ï¼Ÿ","ã‚„ã‚ã¦","å«Œ"])
        base = self.k["k_pos"]*pos + self.k["k_neg"]*neg
        base += self.k["k_neu"]*(1 if pos==0 and neg==0 else 0)

        # æ•´åˆæ€§ï¼šç†±ãŒä½ã„ã®ã«å†—è«‡é€£æ‰“ ç­‰ã‚’å°‘ã—ç½°
        if est["heat"]<0.35 and intent in ["joke","narrow"]:
            base -= self.penalty
        return base

# -------------------------
# ã‚¨ãƒ³ã‚¸ãƒ³
# -------------------------
class Engine:
    def __init__(self, cfg):
        self.cfg = cfg
        self.gen = Genesys(cfg["genesys"])
        self.sti = Stillness(cfg["stillness"])
        self.mot = Motion(cfg["motion"])
        self.coh = Coherence(cfg["coherence"])
        self.mem = Memory()
        self.path = cfg["storage"]["path"]

    def estimate_from_text(self, text:str) -> Dict[str,float]:
        # æœ€å°å®Ÿè£…ï¼šé•·ã•/ç–‘å•/æ„Ÿå˜†/å¦å®šèªã§è¿‘ä¼¼
        L = len(text)
        heat = clamp(0.25 + 0.02*text.count("ï¼") + 0.01*text.count("!")+ 0.001*L, 0,1)
        clarity = clamp(0.6 - 0.15*text.count("ï¼Ÿ") - 0.05*text.count("?"), 0,1)
        affect = clamp(0.55 + 0.1*text.count("ğŸ˜Š") - 0.12*sum(text.count(k) for k in ["å«Œ","ç„¡ç†","ç–²ã‚Œ"]), 0,1)
        return {"heat":heat,"clarity":clarity,"affect":affect}

    def step(self, user_text:str) -> Tuple[str,Dict[str,Any]]:
        est = self.estimate_from_text(user_text)
        intent, conf, detail = self.gen.infer(user_text, est)
        sti = self.sti.decide(intent, conf, detail)

        # å¾…ã¤ï¼ˆä¼šè©±UXï¼šå°ã•ãé–“ã‚’ç½®ã/ã“ã“ã¯å®Ÿæ™‚é–“sleepè¨±å®¹ï¼‰
        if sti["wait"]: time.sleep(sti["wait_sec"])

        # Motion
        policy = self.mot.choose_policy(intent, sti|detail)
        vars = {
            "echo": user_text[:32],
            "key": "è«–ç‚¹",
            "next": "å…·ä½“ä¾‹",
            "quip": random.choice(self.mot.quips),
            "rule": "å®‰å…¨/æ•¬æ„/å¢ƒç•Œã‚’å®ˆã‚‹"
        }
        bot = self.mot.render(policy, vars)

        # Coherence
        reward = self.coh.score_turn(user_text, bot, detail, policy)
        t = Turn(user=user_text, bot=bot, heat=detail["heat"], clarity=detail["clarity"],
                 affect=detail["affect"], intent=policy, reward=reward)
        self.mem.turns.append(t)
        self.mem.policy_scores[policy] += reward

        debug = {"intent":intent,"policy":policy,"confidence":round(conf,3),
                 "gain":round(sti["gain"],3),"wait":sti["wait"],
                 "entropy":round(sti["entropy"],3),"reward":round(reward,3)}
        return bot, debug

    # çŠ¶æ…‹å…¥å‡ºåŠ›
    def save(self):
        data = {
            "turns":[dataclasses.asdict(t) for t in self.mem.turns],
            "policy_scores":self.mem.policy_scores
        }
        with open(self.path,"w",encoding="utf-8") as f: json.dump(data,f,ensure_ascii=False,indent=2)

    def load(self):
        if not os.path.exists(self.path): return
        with open(self.path,"r",encoding="utf-8") as f:
            data=json.load(f)
        dq=deque(maxlen=50)
        for d in data.get("turns",[]): dq.append(Turn(**d))
        self.mem.turns=dq
        self.mem.policy_scores=data.get("policy_scores",self.mem.policy_scores)

# -------------------------
# CLI ãƒ«ãƒ¼ãƒ—
# -------------------------
def main():
    cfg = parse_yaml(DEFAULT_YAML)
    eng = Engine(cfg)
    print("<< ã—ã‚ƒãä¼šè©±ã‚¨ãƒ³ã‚¸ãƒ³ èµ·å‹• >>  /status /reset /save /load ä½¿ãˆã¾ã™ã€‚")

    while True:
        try:
            s = input("\nã‚ãªãŸ> ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nbye!"); break

        if not s: continue
        if s == "/reset":
            eng = Engine(cfg); print("çŠ¶æ…‹ãƒªã‚»ãƒƒãƒˆ"); continue
        if s == "/save":
            eng.save(); print("ä¿å­˜OK"); continue
        if s == "/load":
            eng.load(); print("èª­è¾¼OK"); continue
        if s == "/status":
            ps = sorted(eng.mem.policy_scores.items(), key=lambda x:-x[1])
            print("æ–¹ç­–ã‚¹ã‚³ã‚¢:", ps); 
            if eng.mem.turns:
                last = eng.mem.turns[-1]
                print(f"ç›´è¿‘: intent={last.intent}, reward={round(last.reward,3)}, heat={round(last.heat,2)}")
            continue

        reply, dbg = eng.step(s)
        print(f"ã—ã‚ƒã> {reply}")
        # ãƒ‡ãƒãƒƒã‚°è¦‹ãŸã„æ™‚ã ã‘â†“ã‚³ãƒ¡ãƒ³ãƒˆå¤–ã™
        # print("dbg:", dbg)

if __name__ == "__main__":
    main()
